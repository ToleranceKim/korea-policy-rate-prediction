# ë°ì´í„° ìˆ˜ì§‘ ê°€ì´ë“œ ë° ë¡œì§ ìˆ˜ì • ë°©ë²•

## ğŸ”´ ë¬¸ì œì  ë¶„ì„

### 1. MPB í¬ë¡¤ëŸ¬ ë¬¸ì œì 

#### ğŸ› ì£¼ìš” ë²„ê·¸: í˜ì´ì§€ ìˆ˜ ì œí•œ
```python
# í˜„ì¬ ì½”ë“œ (mpb_crawler_perfect.py:58-66)
if self.start_year >= 2024:
    self.total_pages = 10  # âŒ ë„ˆë¬´ ì ìŒ!
elif self.start_year >= 2020:
    self.total_pages = 30  # âŒ ë¶€ì¡±!
else:
    self.total_pages = 50  # âŒ ì—¬ì „íˆ ë¶€ì¡±!
```

**ë¬¸ì œ**: í•œêµ­ì€í–‰ ì‚¬ì´íŠ¸ëŠ” í˜ì´ì§€ë‹¹ 10ê°œì”© í‘œì‹œí•˜ë¯€ë¡œ, 50í˜ì´ì§€ëŠ” ìµœëŒ€ 500ê°œë§Œ ìˆ˜ì§‘ ê°€ëŠ¥. í•˜ì§€ë§Œ ì‹¤ì œë¡œëŠ” ë” ë§ì€ í˜ì´ì§€ê°€ ìˆì„ ìˆ˜ ìˆìŒ.

#### ğŸ›  í•´ê²° ë°©ë²• 1: í˜ì´ì§€ ìˆ˜ ì¦ê°€
```python
# ìˆ˜ì •ëœ ì½”ë“œ
if self.start_year >= 2024:
    self.total_pages = 30   # 300ê°œê¹Œì§€
elif self.start_year >= 2020:
    self.total_pages = 50   # 500ê°œê¹Œì§€
else:
    self.total_pages = 100  # 1000ê°œê¹Œì§€ (ì¶©ë¶„!)
```

#### ğŸ›  í•´ê²° ë°©ë²• 2: ë™ì  í˜ì´ì§€ ê°ì§€ (ë” ë‚˜ì€ ë°©ë²•)
```python
def parse_first_page(self, response):
    """ì²« í˜ì´ì§€ì—ì„œ ì‹¤ì œ ì „ì²´ í˜ì´ì§€ ìˆ˜ íŒŒì•…"""
    
    # í˜ì´ì§€ë„¤ì´ì…˜ì—ì„œ ë§ˆì§€ë§‰ í˜ì´ì§€ ë²ˆí˜¸ ì°¾ê¸°
    last_page = response.css('div.paging a:last-child::text').get()
    if not last_page:
        # ëŒ€ì²´ ë°©ë²•: onclick ì†ì„±ì—ì„œ í˜ì´ì§€ ë²ˆí˜¸ ì¶”ì¶œ
        last_page_link = response.css('a[onclick*="pageIndex"]:last-child::attr(onclick)').get()
        if last_page_link:
            import re
            match = re.search(r'pageIndex[\'"]?\s*:\s*(\d+)', last_page_link)
            if match:
                last_page = match.group(1)
    
    if last_page:
        self.total_pages = int(last_page)
        self.logger.info(f"ğŸ¯ ì‹¤ì œ ì „ì²´ í˜ì´ì§€ ìˆ˜: {self.total_pages}ê°œ")
    else:
        # ê¸°ë³¸ê°’ ì‚¬ìš©
        self.total_pages = 100
        self.logger.warning(f"âš ï¸ ë§ˆì§€ë§‰ í˜ì´ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ê°’ {self.total_pages} ì‚¬ìš©")
```

---

### 2. ì±„ê¶Œ í¬ë¡¤ëŸ¬ ë¬¸ì œì 

#### ğŸ› ë¬¸ì œ: ë‹¨ì¼ ìŠ¤ë ˆë“œë¡œ ë„ˆë¬´ ëŠë¦¼
í˜„ì¬ `bond_crawling.py`ëŠ” ë©€í‹°ìŠ¤ë ˆë”©ì„ ì§€ì›í•˜ì§€ë§Œ ê¸°ë³¸ì ìœ¼ë¡œ ìˆœì°¨ ì²˜ë¦¬

#### ğŸ›  í•´ê²°: ë³‘ë ¬ ì²˜ë¦¬ í™œì„±í™”
```python
# í˜„ì¬ëŠ” ì£¼ì„ ì²˜ë¦¬ë˜ì–´ ìˆëŠ” ë¶€ë¶„ì„ í™œì„±í™”
from concurrent.futures import ThreadPoolExecutor, as_completed

# ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„ì— ì¶”ê°€
def run_parallel_crawling(pages, max_workers=10):
    """ë³‘ë ¬ í¬ë¡¤ë§ ì‹¤í–‰"""
    all_results = []
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # ê° í˜ì´ì§€ë¥¼ ë³‘ë ¬ë¡œ ì²˜ë¦¬
        futures = []
        for page in range(1, pages + 1):
            url = f"https://finance.naver.com/research/debenture_list.naver?...&page={page}"
            future = executor.submit(process_page, url)
            futures.append(future)
        
        # ê²°ê³¼ ìˆ˜ì§‘
        for future in as_completed(futures):
            try:
                result = future.result()
                all_results.extend(result)
            except Exception as e:
                print(f"Error: {e}")
    
    return all_results
```

---

## ğŸš€ ìˆ˜ì§‘ ì‹¤í–‰ ë°©ë²•

### 1. MPB ì˜ì‚¬ë¡ ìˆ˜ì§‘ (ìˆ˜ì • í›„)

#### Step 1: í¬ë¡¤ëŸ¬ íŒŒì¼ ìˆ˜ì •
```bash
# 1. íŒŒì¼ ì—´ê¸°
nano crawler/MPB/mpb_crawler/spiders/mpb_crawler_perfect.py

# 2. 58-66ë²ˆ ë¼ì¸ì˜ í˜ì´ì§€ ìˆ˜ ë³€ê²½
# self.total_pages = 10 â†’ self.total_pages = 100
```

#### Step 2: ëˆ„ë½ëœ ì˜ì‚¬ë¡ë§Œ ìˆ˜ì§‘
```bash
cd crawler/MPB

# ì „ì²´ ì¬ìˆ˜ì§‘ (ê¶Œì¥)
/opt/anaconda3/envs/ds_env/bin/scrapy crawl mpb_crawler_perfect \
    -a start_year=2014 \
    -a end_year=2025 \
    -o ../../data/mpb_complete_2014_2025.json \
    -s CLOSESPIDER_PAGECOUNT=200 \
    -s LOG_LEVEL=INFO
```

#### Step 3: ê²°ê³¼ í™•ì¸
```bash
# ìˆ˜ì§‘ëœ ê°œìˆ˜ í™•ì¸
cat ../../data/mpb_complete_2014_2025.json | grep -c '"title"'
```

---

### 2. ì±„ê¶Œ ë¦¬í¬íŠ¸ ìˆ˜ì§‘

#### Step 1: ë‚ ì§œë³„ ë¶„í•  ìˆ˜ì§‘ (ì›” ë‹¨ìœ„ ê¶Œì¥)
```bash
cd crawler/BOND

# 2024ë…„ 1ì›” ìˆ˜ì§‘ ì˜ˆì‹œ
/opt/anaconda3/envs/ds_env/bin/python bond_crawling.py 2024-01-01 2024-01-31

# 2024ë…„ 2ì›” ìˆ˜ì§‘
/opt/anaconda3/envs/ds_env/bin/python bond_crawling.py 2024-02-01 2024-02-28
```

#### Step 2: ìë™í™” ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
```bash
# collect_bonds.sh íŒŒì¼ ìƒì„±
cat > collect_bonds.sh << 'EOF'
#!/bin/bash

# ì—°ë„ë³„ ìˆ˜ì§‘
for year in 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 2025; do
    for month in 01 02 03 04 05 06 07 08 09 10 11 12; do
        # ì›”ì˜ ë§ˆì§€ë§‰ ë‚  ê³„ì‚°
        if [ $month -eq 12 ]; then
            end_day=31
        elif [ $month -eq 02 ]; then
            end_day=28
        elif [ $month -eq 04 ] || [ $month -eq 06 ] || [ $month -eq 09 ] || [ $month -eq 11 ]; then
            end_day=30
        else
            end_day=31
        fi
        
        start_date="${year}-${month}-01"
        end_date="${year}-${month}-${end_day}"
        
        echo "ìˆ˜ì§‘ ì¤‘: $start_date ~ $end_date"
        /opt/anaconda3/envs/ds_env/bin/python bond_crawling.py $start_date $end_date
        
        # 30ì´ˆ ëŒ€ê¸° (ì„œë²„ ë¶€í•˜ ë°©ì§€)
        sleep 30
    done
done
EOF

chmod +x collect_bonds.sh
```

#### Step 3: ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
```bash
# ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰
nohup ./collect_bonds.sh > bond_collection.log 2>&1 &

# ì§„í–‰ìƒí™© ëª¨ë‹ˆí„°ë§
tail -f bond_collection.log
```

---

## ğŸ” ìˆ˜ì§‘ ìƒíƒœ í™•ì¸ ë°©ë²•

### MPB ì˜ì‚¬ë¡ í™•ì¸
```python
# check_mpb.py
import json

with open('data/mpb_complete_2014_2025.json', 'r') as f:
    data = json.load(f)

# ì—°ë„ë³„ ì§‘ê³„
from collections import defaultdict
year_counts = defaultdict(int)

for item in data:
    title = item.get('title', '')
    if 'ë…„ë„' in title:
        year = title.split('ë…„ë„')[0].split('(')[-1]
        try:
            year_counts[int(year)] += 1
        except:
            pass

# ëˆ„ë½ í™•ì¸
for year in range(2014, 2026):
    expected = 24  # ì—°ê°„ ì•½ 24íšŒ
    actual = year_counts.get(year, 0)
    if actual < expected:
        print(f"{year}ë…„: {actual}/{expected} (ëˆ„ë½: {expected-actual}ê°œ)")
```

### ì±„ê¶Œ ë¦¬í¬íŠ¸ í™•ì¸
```bash
# PDF íŒŒì¼ ê°œìˆ˜
find . -name "*.pdf" | wc -l

# CSV íŒŒì¼ ê°œìˆ˜
find dataset_2 -name "*.csv" | wc -l

# ë‚ ì§œë³„ ë¶„í¬ í™•ì¸
ls -la *.pdf | awk '{print $6, $7}' | sort | uniq -c
```

---

## âš ï¸ ì£¼ì˜ì‚¬í•­

1. **ì„œë²„ ë¶€í•˜ ë°©ì§€**
   - ìš”ì²­ ê°„ ìµœì†Œ 1-2ì´ˆ ëŒ€ê¸°
   - ë™ì‹œ ìŠ¤ë ˆë“œ 10ê°œ ì´í•˜ ìœ ì§€

2. **ì—ëŸ¬ ì²˜ë¦¬**
   - PDF íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê±´ë„ˆë›°ê¸°
   - ë„¤íŠ¸ì›Œí¬ íƒ€ì„ì•„ì›ƒ 30ì´ˆ ì„¤ì •

3. **ì¤‘ë³µ ë°©ì§€**
   - ì´ë¯¸ ìˆ˜ì§‘ëœ íŒŒì¼ì€ ê±´ë„ˆë›°ê¸°
   - URL ê¸°ë°˜ ì¤‘ë³µ ì²´í¬

---

## ğŸ“Š ì˜ˆìƒ ì†Œìš” ì‹œê°„

| ì‘ì—… | ì˜ˆìƒ ì‹œê°„ | ë¹„ê³  |
|------|----------|------|
| MPB ëˆ„ë½ë¶„ ìˆ˜ì§‘ | 1-2ì‹œê°„ | 64ê°œ |
| ì±„ê¶Œ ë¦¬í¬íŠ¸ (1ë…„) | 2-3ì‹œê°„ | ì•½ 2,500ê°œ |
| ì±„ê¶Œ ë¦¬í¬íŠ¸ (ì „ì²´) | 24-36ì‹œê°„ | ì•½ 30,000ê°œ |

**ê¶Œì¥**: ì±„ê¶Œ ë¦¬í¬íŠ¸ëŠ” ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰í•˜ë©´ì„œ ë‹¤ë¥¸ ì‘ì—… ë³‘í–‰

---

## ğŸ¯ ì¦‰ì‹œ ì‹¤í–‰ ëª…ë ¹ì–´

```bash
# 1. MPB ìˆ˜ì§‘ (í„°ë¯¸ë„ 1)
cd ~/Desktop/my_git/mpb-stance-mining/crawler/MPB
/opt/anaconda3/envs/ds_env/bin/scrapy crawl mpb_crawler_perfect -a start_year=2014 -a end_year=2025 -o ../../data/mpb_fixed.json -s CLOSESPIDER_PAGECOUNT=200

# 2. ì±„ê¶Œ ë¦¬í¬íŠ¸ ìˆ˜ì§‘ (í„°ë¯¸ë„ 2)
cd ~/Desktop/my_git/mpb-stance-mining/crawler/BOND
/opt/anaconda3/envs/ds_env/bin/python bond_crawling.py 2024-01-01 2024-12-31
```